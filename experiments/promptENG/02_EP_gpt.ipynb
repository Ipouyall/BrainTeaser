{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "a21cd0458176406abdcfd68e75248c78": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bd8556c60c8a48128da0ee66d2d55e8c",
       "IPY_MODEL_d058faed26f441d7bf9887b80f9dd4b4",
       "IPY_MODEL_9e78432c1a48456c80faad2a780a5774"
      ],
      "layout": "IPY_MODEL_bb34ad0834a04c8c8565711a98ce6c84"
     }
    },
    "bd8556c60c8a48128da0ee66d2d55e8c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a2805a3c18fd41299c8a848ab04b1c89",
      "placeholder": "​",
      "style": "IPY_MODEL_55be2cebd8684543a6e96a01ac6a7664",
      "value": "  1%"
     }
    },
    "d058faed26f441d7bf9887b80f9dd4b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9a0f611e2f2945859570a739ec2095fb",
      "max": 120,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_62e77e367dff494c81662adafb348942",
      "value": 1
     }
    },
    "9e78432c1a48456c80faad2a780a5774": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fa6f9493db6641e89e45f1cd52335df5",
      "placeholder": "​",
      "style": "IPY_MODEL_a57a72020665426a92b9f2f50f94491d",
      "value": " 1/120 [00:37&lt;1:00:51, 30.68s/it]"
     }
    },
    "bb34ad0834a04c8c8565711a98ce6c84": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a2805a3c18fd41299c8a848ab04b1c89": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "55be2cebd8684543a6e96a01ac6a7664": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9a0f611e2f2945859570a739ec2095fb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "62e77e367dff494c81662adafb348942": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fa6f9493db6641e89e45f1cd52335df5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a57a72020665426a92b9f2f50f94491d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m223.4/223.4 kB\u001B[0m \u001B[31m2.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m75.9/75.9 kB\u001B[0m \u001B[31m8.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m76.9/76.9 kB\u001B[0m \u001B[31m8.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m58.3/58.3 kB\u001B[0m \u001B[31m6.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "llmx 0.0.15a0 requires cohere, which is not installed.\n",
      "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
      "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001B[0m\u001B[31m\n",
      "\u001B[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q -U openai\n",
    "!pip install -q gdown==v4.6.3"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-24T18:30:05.942772Z",
     "start_time": "2024-01-24T18:30:01.420625Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CnzzGtIOvsGs",
    "outputId": "52fcec25-5ba0-44b1-dfdf-2468b5ef2cc7"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "\n",
    "import datetime\n",
    "import time"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-24T18:30:05.950851Z",
     "start_time": "2024-01-24T18:30:05.943927Z"
    },
    "id": "hehDmRAhvsGw"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "GPT_MODEL = \"gpt-4\"\n",
    "DATA_DIR = 'SE2024'\n",
    "INPUT_DATA_PATH  = f'{DATA_DIR}/test_split.csv'\n",
    "OUTPUT_DATA_PATH = f'{DATA_DIR}/infer.jsonl'"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-24T18:30:05.951266Z",
     "start_time": "2024-01-24T18:30:05.946378Z"
    },
    "id": "W5wF0jp-vsGx"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Get dataset"
   ],
   "metadata": {
    "collapsed": false,
    "id": "Gws4a1OIvsGx"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def gdrive_download(file_id, file_name):\n",
    "    !gdown $file_id --output $file_name"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-24T18:30:05.952590Z",
     "start_time": "2024-01-24T18:30:05.950061Z"
    },
    "id": "G_Cxh5_ovsGz"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1JcpBjTXv2OfaG6uYcIJO-Yk69nT9uN8i\n",
      "To: /content/SE2024/test_split.csv\n",
      "\r  0% 0.00/39.0k [00:00<?, ?B/s]\r100% 39.0k/39.0k [00:00<00:00, 97.6MB/s]\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(DATA_DIR):\n",
    "    os.mkdir(DATA_DIR)\n",
    "if not os.path.exists(INPUT_DATA_PATH):\n",
    "    gdrive_download('1JcpBjTXv2OfaG6uYcIJO-Yk69nT9uN8i', INPUT_DATA_PATH)"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-24T18:30:05.959844Z",
     "start_time": "2024-01-24T18:30:05.953587Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cz_NxeeFvsGz",
    "outputId": "73fb20e9-b316-4c79-de32-d5410e1ff1bd"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(INPUT_DATA_PATH)"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-24T18:30:05.967062Z",
     "start_time": "2024-01-24T18:30:05.956297Z"
    },
    "id": "fQcZ5rjOvsG0"
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "id": "alJP8EDovsG0"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Chat Bots"
   ],
   "metadata": {
    "collapsed": false,
    "id": "TwJo3WzDvsG0"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "OPENAI_API_KEY = \"<...>\"\n",
    "\n",
    "class GPTBot:\n",
    "    def __init__(self, model=\"gpt-4\"):\n",
    "        print(\"Initiating GPT chat bot...\")\n",
    "\n",
    "        self.model = model\n",
    "        self.client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "        print(\"GPT chat bot Initiated!\")\n",
    "\n",
    "    def get_completion(self, prompt):\n",
    "        i = 0\n",
    "        while i<10:\n",
    "            i+=1\n",
    "            try:\n",
    "                completion = self.__get_completion_handler(prompt)\n",
    "            except Exception as e:\n",
    "                print(f\"GPT completion failed ::[{datetime.datetime.now()}]::\")\n",
    "                print(e)\n",
    "                time.sleep(10)\n",
    "                print(f\"Trying GPT completion ::[{datetime.datetime.now()}]::\")\n",
    "            else:\n",
    "                break\n",
    "        return completion\n",
    "\n",
    "    def __get_completion_handler(self, prompt):\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=messages,\n",
    "            temperature=0, # this is the degree of randomness of the model's output\n",
    "        )\n",
    "        return response.choices[0].message.content"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-24T18:30:05.973186Z",
     "start_time": "2024-01-24T18:30:05.964154Z"
    },
    "id": "vdUDwZZHvsG0"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prompt Setup"
   ],
   "metadata": {
    "id": "ZOn1CfT8BFQ4"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "base_prompt = \"\"\"\n",
    "You are given a riddle and four options to choose the answer amongst them. A riddle is a question or statement intentionally phrased so as to require ingenuity in ascertaining its answer or meaning, typically presented as a game.\n",
    "Different ideas can be used in these riddles:\n",
    "    1. Riddles often employ misdirection, leading you away from the actual solution.\n",
    "    2. They include elements with double meanings, requiring a keen eye for words with dual interpretations.\n",
    "    3. Metaphorical wordplay adds another layer, urging you to decipher figurative language.\n",
    "    4. Look out for exaggeration, as riddles may present overly dramatic details to divert your attention.\n",
    "    5. Common phrases and sayings may hide within the puzzle, demanding familiarity.\n",
    "    6. Associations and irony play a crucial role, introducing unexpected connections.\n",
    "    7. Numerical puzzles can also be part of the mystery, requiring you to decode their significance.\n",
    "    8. Elemental imagery, drawn from nature, might hold key descriptors.\n",
    "    9. Rhyming and sound clues can add a poetic dimension.\n",
    "    10. Avoid sexism ans sex cliche, for example, gender bias for jobs, based on their positions or their outcome.\n",
    "    11. Also, it is important to note you should decode the upcoming riddle using everyday logic and creativity.\n",
    "Although a clever solution is required, avoid supernatural solutions and keep your answer within the limits of realistic imagination. For example, having superhuman abilities or unusual events or things are mostly a not preferred choice unless that is a better solution. Now which of the following options is the answer to the following riddle:\n",
    "\n",
    "to solve the riddle, consider mentioned pont above and think step by step for each option, and it the end, mention the option you think is the best, in the format: 'Option 1' or 'Option 2' or 'Option 3' or 'Option 4'\n",
    "\n",
    "\n",
    "Riddle: \"{RIDDLE}\"\n",
    "\n",
    "Options:\n",
    "Option 1: \"{OPTION_1}\"\n",
    "Option 2: \"{OPTION_2}\"\n",
    "Option 3: \"{OPTION_3}\"\n",
    "Option 4: \"None of the above options are correct\"\n",
    "\n",
    "\n",
    "Let's think step by step about each option, then at the end, choose the best and the most logical option:\n",
    "\"\"\"\n",
    "\n",
    "def get_prompt(ds):\n",
    "    return base_prompt.format(\n",
    "            RIDDLE=ds['QUESTION'],\n",
    "            OPTION_1=ds['OPTION 1'],\n",
    "            OPTION_2=ds['OPTION 2'],\n",
    "            OPTION_3=ds['OPTION 3'],\n",
    "    )\n"
   ],
   "metadata": {
    "id": "DQENRkzmA0An",
    "ExecuteTime": {
     "end_time": "2024-01-24T18:30:05.973802Z",
     "start_time": "2024-01-24T18:30:05.967326Z"
    }
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Read/Write utils"
   ],
   "metadata": {
    "collapsed": false,
    "id": "cELCx7WkvsG2"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def save_inference(data, address):\n",
    "    with open(address, 'w') as jsonl_file:\n",
    "        for item in data:\n",
    "            jsonl_file.write(json.dumps(item) + '\\n')"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-24T18:30:05.973897Z",
     "start_time": "2024-01-24T18:30:05.969743Z"
    },
    "id": "NGAjEp8TvsG2"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def add_inference(data, address):\n",
    "    with open(address, 'a+') as jsonl_file:\n",
    "        for item in data:\n",
    "            jsonl_file.write(json.dumps(item) + '\\n')"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-24T18:30:05.974728Z",
     "start_time": "2024-01-24T18:30:05.972219Z"
    },
    "id": "F3Vlm980vsG2"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def read_inference(address):\n",
    "    json_list = []\n",
    "    with open(address, 'r') as file:\n",
    "        for line in file:\n",
    "            data = json.loads(line)\n",
    "            json_list.append(data)\n",
    "    return json_list"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-24T18:30:05.976188Z",
     "start_time": "2024-01-24T18:30:05.974158Z"
    },
    "id": "fwBRFr2SvsG3"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Experiment"
   ],
   "metadata": {
    "collapsed": false,
    "id": "X4ukwdBnvsG3"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "if os.path.exists(OUTPUT_DATA_PATH):\n",
    "    results = read_inference(OUTPUT_DATA_PATH)\n",
    "\n",
    "    print(f\"Records recovered from {OUTPUT_DATA_PATH}\")\n",
    "    print(f\".::{len(results)} records::.\")"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-24T18:30:05.986019Z",
     "start_time": "2024-01-24T18:30:05.976497Z"
    },
    "id": "0V5TxSfuvsG3"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Initiating GPT chat bot...\n",
      "GPT chat bot Initiated!\n"
     ]
    }
   ],
   "source": [
    "chat_bot = GPTBot(model=GPT_MODEL)"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-24T18:30:05.986620Z",
     "start_time": "2024-01-24T18:30:05.978942Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0mOPf_R-vsG4",
    "outputId": "fe93c24e-9b0d-48cf-bd1e-4d801f30b29e"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Execute experiment"
   ],
   "metadata": {
    "collapsed": false,
    "id": "_SIfvNqMvsG4"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/120 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a21cd0458176406abdcfd68e75248c78"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-31-fb585ef82839>\u001B[0m in \u001B[0;36m<cell line: 3>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m     \u001B[0mprompt\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_prompt\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 8\u001B[0;31m     \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mchat_bot\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_completion\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprompt\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      9\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m     data = {\n",
      "\u001B[0;32m<ipython-input-29-f6717126e870>\u001B[0m in \u001B[0;36mget_completion\u001B[0;34m(self, prompt)\u001B[0m\n\u001B[1;32m     16\u001B[0m             \u001B[0mi\u001B[0m\u001B[0;34m+=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     17\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 18\u001B[0;31m                 \u001B[0mcompletion\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__get_completion_handler\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprompt\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     19\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     20\u001B[0m                 \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"GPT completion failed ::[{datetime.datetime.now()}]::\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-29-f6717126e870>\u001B[0m in \u001B[0;36m__get_completion_handler\u001B[0;34m(self, prompt)\u001B[0m\n\u001B[1;32m     28\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__get_completion_handler\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mprompt\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     29\u001B[0m         \u001B[0mmessages\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m{\u001B[0m\u001B[0;34m\"role\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;34m\"user\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"content\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mprompt\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 30\u001B[0;31m         response = self.client.chat.completions.create(\n\u001B[0m\u001B[1;32m     31\u001B[0m             \u001B[0mmodel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     32\u001B[0m             \u001B[0mmessages\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmessages\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    269\u001B[0m                         \u001B[0mmsg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    270\u001B[0m                 \u001B[0;32mraise\u001B[0m \u001B[0mTypeError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmsg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 271\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    272\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    273\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mwrapper\u001B[0m  \u001B[0;31m# type: ignore\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\u001B[0m in \u001B[0;36mcreate\u001B[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001B[0m\n\u001B[1;32m    646\u001B[0m         \u001B[0mtimeout\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mfloat\u001B[0m \u001B[0;34m|\u001B[0m \u001B[0mhttpx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTimeout\u001B[0m \u001B[0;34m|\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;34m|\u001B[0m \u001B[0mNotGiven\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mNOT_GIVEN\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    647\u001B[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001B[0;32m--> 648\u001B[0;31m         return self._post(\n\u001B[0m\u001B[1;32m    649\u001B[0m             \u001B[0;34m\"/chat/completions\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    650\u001B[0m             body=maybe_transform(\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001B[0m in \u001B[0;36mpost\u001B[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1177\u001B[0m             \u001B[0mmethod\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"post\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0murl\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mjson_data\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mbody\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfiles\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mto_httpx_files\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfiles\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0moptions\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1178\u001B[0m         )\n\u001B[0;32m-> 1179\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mcast\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mResponseT\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrequest\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcast_to\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mopts\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstream\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstream\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstream_cls\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstream_cls\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1180\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1181\u001B[0m     def patch(\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001B[0m in \u001B[0;36mrequest\u001B[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[1;32m    866\u001B[0m         \u001B[0mstream_cls\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mtype\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0m_StreamT\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m|\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    867\u001B[0m     ) -> ResponseT | _StreamT:\n\u001B[0;32m--> 868\u001B[0;31m         return self._request(\n\u001B[0m\u001B[1;32m    869\u001B[0m             \u001B[0mcast_to\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcast_to\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    870\u001B[0m             \u001B[0moptions\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0moptions\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001B[0m in \u001B[0;36m_request\u001B[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[1;32m    895\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    896\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 897\u001B[0;31m             response = self._client.send(\n\u001B[0m\u001B[1;32m    898\u001B[0m                 \u001B[0mrequest\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    899\u001B[0m                 \u001B[0mstream\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstream\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_should_stream_response_body\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrequest\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mrequest\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_client.py\u001B[0m in \u001B[0;36msend\u001B[0;34m(self, request, stream, auth, follow_redirects)\u001B[0m\n\u001B[1;32m    913\u001B[0m         \u001B[0mauth\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_build_request_auth\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrequest\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mauth\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    914\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 915\u001B[0;31m         response = self._send_handling_auth(\n\u001B[0m\u001B[1;32m    916\u001B[0m             \u001B[0mrequest\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    917\u001B[0m             \u001B[0mauth\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mauth\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_client.py\u001B[0m in \u001B[0;36m_send_handling_auth\u001B[0;34m(self, request, auth, follow_redirects, history)\u001B[0m\n\u001B[1;32m    941\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    942\u001B[0m             \u001B[0;32mwhile\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 943\u001B[0;31m                 response = self._send_handling_redirects(\n\u001B[0m\u001B[1;32m    944\u001B[0m                     \u001B[0mrequest\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    945\u001B[0m                     \u001B[0mfollow_redirects\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mfollow_redirects\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_client.py\u001B[0m in \u001B[0;36m_send_handling_redirects\u001B[0;34m(self, request, follow_redirects, history)\u001B[0m\n\u001B[1;32m    978\u001B[0m                 \u001B[0mhook\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrequest\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    979\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 980\u001B[0;31m             \u001B[0mresponse\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_send_single_request\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrequest\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    981\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    982\u001B[0m                 \u001B[0;32mfor\u001B[0m \u001B[0mhook\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_event_hooks\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"response\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_client.py\u001B[0m in \u001B[0;36m_send_single_request\u001B[0;34m(self, request)\u001B[0m\n\u001B[1;32m   1014\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1015\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mrequest_context\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrequest\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mrequest\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1016\u001B[0;31m             \u001B[0mresponse\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtransport\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhandle_request\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrequest\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1017\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1018\u001B[0m         \u001B[0;32massert\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mresponse\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstream\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mSyncByteStream\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_transports/default.py\u001B[0m in \u001B[0;36mhandle_request\u001B[0;34m(self, request)\u001B[0m\n\u001B[1;32m    229\u001B[0m         )\n\u001B[1;32m    230\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mmap_httpcore_exceptions\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 231\u001B[0;31m             \u001B[0mresp\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_pool\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhandle_request\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mreq\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    232\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    233\u001B[0m         \u001B[0;32massert\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mresp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstream\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtyping\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mIterable\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/connection_pool.py\u001B[0m in \u001B[0;36mhandle_request\u001B[0;34m(self, request)\u001B[0m\n\u001B[1;32m    266\u001B[0m                 \u001B[0;32mwith\u001B[0m \u001B[0mShieldCancellation\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    267\u001B[0m                     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mresponse_closed\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstatus\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 268\u001B[0;31m                 \u001B[0;32mraise\u001B[0m \u001B[0mexc\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    269\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    270\u001B[0m                 \u001B[0;32mbreak\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/connection_pool.py\u001B[0m in \u001B[0;36mhandle_request\u001B[0;34m(self, request)\u001B[0m\n\u001B[1;32m    249\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    250\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 251\u001B[0;31m                 \u001B[0mresponse\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconnection\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhandle_request\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrequest\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    252\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mConnectionNotAvailable\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    253\u001B[0m                 \u001B[0;31m# The ConnectionNotAvailable exception is a special case, that\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/connection.py\u001B[0m in \u001B[0;36mhandle_request\u001B[0;34m(self, request)\u001B[0m\n\u001B[1;32m    101\u001B[0m                 \u001B[0;32mraise\u001B[0m \u001B[0mConnectionNotAvailable\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    102\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 103\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_connection\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhandle_request\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrequest\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    104\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    105\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_connect\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrequest\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mRequest\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mNetworkStream\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/http11.py\u001B[0m in \u001B[0;36mhandle_request\u001B[0;34m(self, request)\u001B[0m\n\u001B[1;32m    131\u001B[0m                 \u001B[0;32mwith\u001B[0m \u001B[0mTrace\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"response_closed\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlogger\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrequest\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mtrace\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    132\u001B[0m                     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_response_closed\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 133\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0mexc\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    134\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    135\u001B[0m     \u001B[0;31m# Sending the request...\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/http11.py\u001B[0m in \u001B[0;36mhandle_request\u001B[0;34m(self, request)\u001B[0m\n\u001B[1;32m    109\u001B[0m                     \u001B[0mreason_phrase\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    110\u001B[0m                     \u001B[0mheaders\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 111\u001B[0;31m                 ) = self._receive_response_headers(**kwargs)\n\u001B[0m\u001B[1;32m    112\u001B[0m                 trace.return_value = (\n\u001B[1;32m    113\u001B[0m                     \u001B[0mhttp_version\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/http11.py\u001B[0m in \u001B[0;36m_receive_response_headers\u001B[0;34m(self, request)\u001B[0m\n\u001B[1;32m    174\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    175\u001B[0m         \u001B[0;32mwhile\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 176\u001B[0;31m             \u001B[0mevent\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_receive_event\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    177\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mevent\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mh11\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mResponse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    178\u001B[0m                 \u001B[0;32mbreak\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/http11.py\u001B[0m in \u001B[0;36m_receive_event\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    210\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    211\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mevent\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0mh11\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mNEED_DATA\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 212\u001B[0;31m                 data = self._network_stream.read(\n\u001B[0m\u001B[1;32m    213\u001B[0m                     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mREAD_NUM_BYTES\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    214\u001B[0m                 )\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_backends/sync.py\u001B[0m in \u001B[0;36mread\u001B[0;34m(self, max_bytes, timeout)\u001B[0m\n\u001B[1;32m    124\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mmap_exceptions\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mexc_map\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    125\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_sock\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msettimeout\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 126\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_sock\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrecv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmax_bytes\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    127\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    128\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mwrite\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbuffer\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mbytes\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mtyping\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mOptional\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mfloat\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/lib/python3.10/ssl.py\u001B[0m in \u001B[0;36mrecv\u001B[0;34m(self, buflen, flags)\u001B[0m\n\u001B[1;32m   1286\u001B[0m                     \u001B[0;34m\"non-zero flags not allowed in calls to recv() on %s\"\u001B[0m \u001B[0;34m%\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1287\u001B[0m                     self.__class__)\n\u001B[0;32m-> 1288\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbuflen\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1289\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1290\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrecv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbuflen\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mflags\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/lib/python3.10/ssl.py\u001B[0m in \u001B[0;36mread\u001B[0;34m(self, len, buffer)\u001B[0m\n\u001B[1;32m   1159\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_sslobj\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbuffer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1160\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1161\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_sslobj\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1162\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mSSLError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1163\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mSSL_ERROR_EOF\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msuppress_ragged_eofs\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "start = len(results)\n",
    "\n",
    "for idx, (index, ds) in enumerate(tqdm(dataset.iterrows(), total=len(dataset)), start=1):\n",
    "    if idx <= start:\n",
    "        continue\n",
    "\n",
    "    prompt = get_prompt(ds)\n",
    "    result = chat_bot.get_completion(prompt)\n",
    "\n",
    "    data = {\n",
    "        \"question\": ds['QUESTION'],\n",
    "        'option 1': ds['OPTION 1'],\n",
    "        'option 2': ds['OPTION 2'],\n",
    "        'option 3': ds['OPTION 3'],\n",
    "        'option 4': ds['OPTION 4'],\n",
    "        'gpt': result\n",
    "    }\n",
    "    add_inference([data], OUTPUT_DATA_PATH)\n",
    "save_inference(results, OUTPUT_DATA_PATH)\n",
    "\n",
    "print(f\"Dumped {len(results)} records to {OUTPUT_DATA_PATH}\")"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-24T18:30:09.909698Z",
     "start_time": "2024-01-24T18:30:05.984404Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417,
     "referenced_widgets": [
      "a21cd0458176406abdcfd68e75248c78",
      "bd8556c60c8a48128da0ee66d2d55e8c",
      "d058faed26f441d7bf9887b80f9dd4b4",
      "9e78432c1a48456c80faad2a780a5774",
      "bb34ad0834a04c8c8565711a98ce6c84",
      "a2805a3c18fd41299c8a848ab04b1c89",
      "55be2cebd8684543a6e96a01ac6a7664",
      "9a0f611e2f2945859570a739ec2095fb",
      "62e77e367dff494c81662adafb348942",
      "fa6f9493db6641e89e45f1cd52335df5",
      "a57a72020665426a92b9f2f50f94491d"
     ]
    },
    "id": "hj3IUWBtvsG5",
    "outputId": "c0fd33eb-fe8e-47df-a222-ce72216bbfa5"
   }
  }
 ]
}
