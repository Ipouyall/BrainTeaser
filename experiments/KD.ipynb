{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# Utils"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-28T15:23:10.974681Z",
     "start_time": "2023-10-28T15:23:10.916891Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import datetime\n",
    "import time"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-28T15:23:11.305682Z",
     "start_time": "2023-10-28T15:23:10.922806Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Chat Bots"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "OxvrKB6FAwPk",
    "ExecuteTime": {
     "end_time": "2023-10-28T15:23:11.379821Z",
     "start_time": "2023-10-28T15:23:11.306833Z"
    }
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "\n",
    "class GPTBot:\n",
    "    def __init__(self, model=\"gpt-4\"):\n",
    "        print(\"Initiating GPT chat bot...\")\n",
    "\n",
    "        from secret_keys import OPENAI_API_KEY\n",
    "        openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "        self.model = model\n",
    "        print(\"GPT chat bot Initiated!\")\n",
    "\n",
    "    def get_completion(self, prompt):\n",
    "        while True:\n",
    "            try:\n",
    "                completion = self.__get_completion_handler(prompt)\n",
    "            except:\n",
    "                print(f\"GPT completion failed ::[{datetime.datetime.now()}]::\")\n",
    "                time.sleep(10)\n",
    "                print(f\"Trying GPT completion ::[{datetime.datetime.now()}]::\")\n",
    "            else:\n",
    "                break\n",
    "        return completion\n",
    "\n",
    "    def __get_completion_handler(self, prompt):\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=self.model,\n",
    "            messages=messages,\n",
    "            temperature=0, # this is the degree of randomness of the model's output\n",
    "        )\n",
    "        return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import pyperclip\n",
    "\n",
    "class CopyCatBot:\n",
    "    def __init__(self):\n",
    "        print(\"CopyCatBot Initiated!\")\n",
    "\n",
    "    @staticmethod\n",
    "    def get_completion(prompt):\n",
    "        pyperclip.copy(prompt)\n",
    "\n",
    "        while True:\n",
    "            completion = pyperclip.paste()\n",
    "            if completion != prompt:\n",
    "                prompt(f\"Completion completed ::[{datetime.datetime.now()}]::\")\n",
    "                return completion\n",
    "            else:\n",
    "                print(f\"Waiting for completion, same entry as prompt ::[{datetime.datetime.now()}]::\")\n",
    "\n",
    "            pyperclip.copy(prompt)\n",
    "            time.sleep(20)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-28T15:23:11.383037Z",
     "start_time": "2023-10-28T15:23:11.380572Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sentence Puzzle"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "from enum import Enum, auto\n",
    "\n",
    "class ModeQ(Enum):\n",
    "    Train = auto()\n",
    "    Test = auto()\n",
    "\n",
    "@dataclass()\n",
    "class SentencePuzzle:\n",
    "    id: str\n",
    "    question: str\n",
    "    answer: str\n",
    "    label: int\n",
    "    choices: List[str]\n",
    "    choice_order: List[int]\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.answer is None:\n",
    "            self.mode = ModeQ.Test\n",
    "        else:\n",
    "            self.mode = ModeQ.Train\n",
    "\n",
    "\n",
    "def load_sentence_puzzles(file_path: str) -> list[SentencePuzzle]:\n",
    "    print(f\"Loading sentence puzzles from {file_path}\")\n",
    "    sps = np.load(file_path, allow_pickle=True)\n",
    "    puzzles = [\n",
    "        SentencePuzzle(\n",
    "            id=sp['id'],\n",
    "            question=sp['question'],\n",
    "            answer=sp.get('answer', None),\n",
    "            label=sp.get('label', None),\n",
    "            choices=sp['choice_list'],\n",
    "            choice_order=sp.get('choice_order', None)\n",
    "        )\n",
    "        for sp in sps]\n",
    "    print(f\"Loaded {len(puzzles)} sentence puzzles\")\n",
    "    return puzzles\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-28T15:23:11.387274Z",
     "start_time": "2023-10-28T15:23:11.385803Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prompt Setup"
   ],
   "metadata": {
    "id": "ZOn1CfT8BFQ4"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "question = \"A man shaves everyday, yet keeps his beard long.\"\n",
    "answer = \"He wants to maintain his appearance.\"\n",
    "\n",
    "base_prompt = \"\"\"\n",
    "Your task is to generate a descriptive explanation from a question to an answer option. \\\n",
    "In the following, a question and an option as the answer to the question is provided. \\\n",
    "The answer might be or not be a correct answer.\n",
    "\n",
    "Write a descriptive explanation in at most one paragraph and 200 words to show that path from question to the answer.\n",
    "\n",
    "Question: ```{question}```\n",
    "Answer Option: ```{option}```\n",
    "\"\"\"\n",
    "\n",
    "generate_prompt_baseline = lambda que, opt: base_prompt.format(question=que, option=opt)\n",
    "\n",
    "# response = get_completion(prompt)\n",
    "# print(generate_prompt_baseline(question,answer))\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DQENRkzmA0An",
    "outputId": "3a6fdec3-0f68-48a9-a233-5e9d97d4e5ae",
    "ExecuteTime": {
     "end_time": "2023-10-28T15:23:11.389080Z",
     "start_time": "2023-10-28T15:23:11.388133Z"
    }
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Experiment"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Config"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "Demo = False\n",
    "PromptMode = \"baseline\"\n",
    "Phase = [\"train\", \"test\"][0]\n",
    "GPT_MODEL = \"gpt-4\"\n",
    "\n",
    "QuestionsPath = {\n",
    "    \"train\": \"../datasets/data/SP-train.npy\",\n",
    "    \"test\": \"../datasets/data/SP-val-nolabel.npy\"\n",
    "}[Phase]\n",
    "\n",
    "DumpDir = \"SentencePuzzleKD\"\n",
    "DumpPath = os.path.join(DumpDir, \"KD_\" + Phase + \"_\" + GPT_MODEL.replace(\".\", \"\") + \".csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-28T15:23:11.391528Z",
     "start_time": "2023-10-28T15:23:11.390133Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SetUP"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"Initiating experiments pipeline...\")\n",
    "\n",
    "if Demo:\n",
    "    chat_bot = CopyCatBot()\n",
    "else:\n",
    "    chat_bot = GPTBot(model=GPT_MODEL)\n",
    "\n",
    "if PromptMode == \"baseline\":\n",
    "    prompt_generator = generate_prompt_baseline\n",
    "else:\n",
    "    print(f\"Unknown prompt generating method: {PromptMode}\")\n",
    "    raise Exception()\n",
    "\n",
    "if not os.path.exists(DumpDir):\n",
    "    os.mkdir(DumpDir)\n",
    "    print(\"DumpDir created\")\n",
    "\n",
    "puzzles = load_sentence_puzzles(QuestionsPath)"
   ],
   "metadata": {
    "id": "_809duiZ_6qU",
    "ExecuteTime": {
     "end_time": "2023-10-28T15:23:11.396835Z",
     "start_time": "2023-10-28T15:23:11.392505Z"
    }
   },
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating experiments pipeline...\n",
      "Initiating GPT chat bot...\n",
      "GPT chat bot Initiated!\n",
      "Loading sentence puzzles from ../datasets/data/SP-train.npy\n",
      "Loaded 507 sentence puzzles\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train mode!\n",
      "Records recovered from SentencePuzzleKD/KD_train_gpt-4.csv\n",
      ".::318 records::.\n"
     ]
    }
   ],
   "source": [
    "kd_report = {\n",
    "    \"id\": list(),\n",
    "    \"question\": list(),\n",
    "    \"option_1\": list(),\n",
    "    \"hypothesis_1\": list(),\n",
    "    \"option_2\": list(),\n",
    "    \"hypothesis_2\": list(),\n",
    "    \"option_3\": list(),\n",
    "    \"hypothesis_3\": list(),\n",
    "    \"option_4\": list(),\n",
    "}\n",
    "\n",
    "if Phase == \"train\":\n",
    "    kd_report[\"answer\"] = list()\n",
    "    kd_report[\"label\"] = list()\n",
    "    print(\"Train mode!\")\n",
    "\n",
    "\n",
    "if os.path.exists(DumpPath):\n",
    "    df = pd.read_csv(DumpPath)\n",
    "    for col in kd_report.keys():\n",
    "        kd_report[col] = df[col].tolist()\n",
    "\n",
    "    print(f\"Records recovered from {DumpPath}\")\n",
    "    print(f\".::{len(kd_report['id'])} records::.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-28T15:23:11.425173Z",
     "start_time": "2023-10-28T15:23:11.398247Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Execute experiment"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/189 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "460147f79f6740ea81534f7b9f73ff9e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT completion failed .::2023-10-28 19:03:11.756972::.\n",
      "Trying GPT completion .::2023-10-28 19:03:21.763782::.\n",
      "GPT completion failed .::2023-10-28 19:07:56.942900::.\n",
      "Trying GPT completion .::2023-10-28 19:08:06.951543::.\n",
      "GPT completion failed .::2023-10-28 19:18:07.625509::.\n",
      "Trying GPT completion .::2023-10-28 19:18:17.635369::.\n",
      "GPT completion failed .::2023-10-28 19:34:29.923134::.\n",
      "Trying GPT completion .::2023-10-28 19:34:39.928912::.\n",
      "GPT completion failed .::2023-10-28 19:44:40.221252::.\n",
      "Trying GPT completion .::2023-10-28 19:44:50.228696::.\n",
      "GPT completion failed .::2023-10-28 19:54:50.365225::.\n",
      "Trying GPT completion .::2023-10-28 19:55:00.368172::.\n",
      "GPT completion failed .::2023-10-28 20:11:11.728753::.\n",
      "Trying GPT completion .::2023-10-28 20:11:21.732138::.\n",
      "GPT completion failed .::2023-10-28 20:21:21.904876::.\n",
      "Trying GPT completion .::2023-10-28 20:21:31.910293::.\n",
      "GPT completion failed .::2023-10-28 20:32:47.124953::.\n",
      "Trying GPT completion .::2023-10-28 20:32:57.129978::.\n",
      "GPT completion failed .::2023-10-28 20:46:14.483315::.\n",
      "Trying GPT completion .::2023-10-28 20:46:24.488490::.\n",
      "GPT completion failed .::2023-10-28 20:56:24.594614::.\n",
      "Trying GPT completion .::2023-10-28 20:56:34.597590::.\n",
      "GPT completion failed .::2023-10-28 21:06:34.709571::.\n",
      "Trying GPT completion .::2023-10-28 21:06:44.711527::.\n",
      "GPT completion failed .::2023-10-28 21:16:44.839209::.\n",
      "Trying GPT completion .::2023-10-28 21:16:54.849342::.\n",
      "GPT completion failed .::2023-10-28 21:26:55.245146::.\n",
      "Trying GPT completion .::2023-10-28 21:27:05.245755::.\n",
      "GPT completion failed .::2023-10-28 21:37:05.443290::.\n",
      "Trying GPT completion .::2023-10-28 21:37:15.443639::.\n",
      "GPT completion failed .::2023-10-28 21:47:15.675900::.\n",
      "Trying GPT completion .::2023-10-28 21:47:25.681359::.\n",
      "GPT completion failed .::2023-10-28 22:06:49.310339::.\n",
      "Trying GPT completion .::2023-10-28 22:06:59.320868::.\n",
      "GPT completion failed .::2023-10-28 22:16:59.453261::.\n",
      "Trying GPT completion .::2023-10-28 22:17:09.458615::.\n",
      "GPT completion failed .::2023-10-28 22:27:09.574758::.\n",
      "Trying GPT completion .::2023-10-28 22:27:19.575230::.\n",
      "GPT completion failed .::2023-10-28 22:37:19.704978::.\n",
      "Trying GPT completion .::2023-10-28 22:37:29.708714::.\n",
      "GPT completion failed .::2023-10-28 22:47:29.914540::.\n",
      "Trying GPT completion .::2023-10-28 22:47:39.920484::.\n",
      "GPT completion failed .::2023-10-28 22:58:55.510644::.\n",
      "Trying GPT completion .::2023-10-28 22:59:05.512738::.\n",
      "GPT completion failed .::2023-10-28 23:15:20.923026::.\n",
      "Trying GPT completion .::2023-10-28 23:15:30.928254::.\n",
      "GPT completion failed .::2023-10-28 23:52:02.156876::.\n",
      "Trying GPT completion .::2023-10-28 23:52:12.160321::.\n",
      "GPT completion failed .::2023-10-29 00:08:49.553869::.\n",
      "Trying GPT completion .::2023-10-29 00:08:59.558200::.\n",
      "GPT completion failed .::2023-10-29 00:18:59.703035::.\n",
      "Trying GPT completion .::2023-10-29 00:19:09.705659::.\n",
      "GPT completion failed .::2023-10-29 00:32:20.585556::.\n",
      "Trying GPT completion .::2023-10-29 00:32:30.590991::.\n",
      "GPT completion failed .::2023-10-29 00:45:42.707604::.\n",
      "Trying GPT completion .::2023-10-29 00:45:52.710171::.\n",
      "GPT completion failed .::2023-10-29 00:55:52.870027::.\n",
      "Trying GPT completion .::2023-10-29 00:56:02.875562::.\n",
      "GPT completion failed .::2023-10-29 01:06:03.012390::.\n",
      "Trying GPT completion .::2023-10-29 01:06:13.018103::.\n",
      "GPT completion failed .::2023-10-29 01:12:46.577353::.\n"
     ]
    }
   ],
   "source": [
    "start = len(kd_report['id'])\n",
    "length = len(puzzles)\n",
    "\n",
    "for idx in tqdm(range(start, length)):\n",
    "    puzzle = puzzles[idx]\n",
    "\n",
    "    kd_report['id'].append(puzzle.id)\n",
    "    kd_report['question'].append(puzzle.question)\n",
    "\n",
    "    for i in [1, 2, 3]:\n",
    "        put = f\"option_{i}\"\n",
    "        het = f\"hypothesis_{i}\"\n",
    "\n",
    "        option = puzzle.choices[i - 1]\n",
    "        prompt = prompt_generator(que=puzzle.question, opt=option)\n",
    "        hypothesis = chat_bot.get_completion(prompt)\n",
    "        kd_report[put].append(option)\n",
    "        kd_report[het].append(hypothesis)\n",
    "\n",
    "    put = \"option_4\"\n",
    "    option = puzzle.choices[3]\n",
    "    kd_report[put].append(option)\n",
    "\n",
    "    if Phase == \"train\":\n",
    "        kd_report['answer'].append(puzzle.answer)\n",
    "        kd_report[\"label\"].append(puzzle.label+1)\n",
    "\n",
    "    df = pd.DataFrame(kd_report)\n",
    "    df.to_csv(DumpPath, index=False)\n",
    "\n",
    "print(f\"Dumped {idx+1} records to {DumpPath}\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-10-28T15:23:11.411149Z"
    }
   }
  }
 ]
}
